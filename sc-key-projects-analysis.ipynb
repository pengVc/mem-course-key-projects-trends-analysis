{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91cf2f9f-ed1b-4166-8d9c-92719f6e49e7",
   "metadata": {},
   "source": [
    "## 1. æ•°æ®é¢„å¤„ç†\n",
    "\n",
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0841abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ§åˆ¶è°ƒè¯•è¾“å‡ºçš„å¼€å…³\n",
    "DEBUG = not False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca5e11",
   "metadata": {},
   "source": [
    "### 1.1 é…ç½®å‚æ•° \n",
    "> éœ€æ ¹æ®å®é™…æ–‡ä»¶è·¯å¾„ä¿®æ”¹\n",
    "- éœ€è¦è§£æ PDF æ–‡ä»¶è·¯å¾„\n",
    "- è¾“å‡ºæ–‡ä»¶ CSV è·¯å¾„\n",
    "- è¾“å‡ºæ–‡ä»¶ CSV è¡¨å¤´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "17254b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_PDF_PATH = \"./assets/2024å¹´å››å·çœé‡ç‚¹é¡¹ç›®åå•.pdf\"  \n",
    "CONST_OUTPUT_DIR = \"./outputs\"\n",
    "CONST_ORIGIN_HEADERS = [\"æ€»åºå·\", \"åˆ†åºå·\", \"é¡¹ç›®åç§°\", \"å»ºè®¾åœ°å€\"]\n",
    "CONST_TARGET_HEADERS = [\"é¡¹ç›®åç§°\", \"å»ºè®¾åœ°å€\", \"ä¸€çº§é¡¹ç›®é¢†åŸŸ\", \"äºŒçº§é¡¹ç›®é¢†åŸŸ\", \"ä¸‰çº§é¡¹ç›®é¢†åŸŸ\", \"å»ºè®¾æ€§è´¨\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f35ba",
   "metadata": {},
   "source": [
    "### 1.2 ä½¿ç”¨ pdfplumber è§£æ PDF é¡µé¢æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dc2d276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è°ƒè¯• pdfplumber\n",
    "import pdfplumber\n",
    "\n",
    "if False:\n",
    "    with pdfplumber.open(CONST_PDF_PATH) as pdf:\n",
    "        page = pdf.pages[0]\n",
    "        img = page.crop(bbox=[0, 0, 584, 142]).to_image() \n",
    "        img.show()  # æ˜¾ç¤ºå›¾åƒï¼Œæ‰‹åŠ¨è§‚å¯Ÿå¹¶ä¼°ç®—åæ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "acd26e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "# ç”³æ˜ä¸€ä¸ª(ä¸Šä¸‹æ–‡)å˜é‡ï¼Œä¸€çº§é¡¹ç›®é¢†åŸŸï¼Œç±»å‹ä¸ºå­—ç¬¦ä¸²\n",
    "Level_1_Project_Domain = \"\"\n",
    "Level_2_Project_Domain = \"\"\n",
    "Level_3_Project_Domain = \"\"\n",
    "\n",
    "def extract_table_from_pdf(pdf_path):\n",
    "    result_key_project_list = []  # å­˜å‚¨æ‰€æœ‰é¡µé¢çš„è¡¨æ ¼æ•°æ®\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # è·å–å®é™…æ€»é¡µæ•°\n",
    "        total_pages = len(pdf.pages)  \n",
    "        \n",
    "        # éå†PDFçš„æ¯ä¸€é¡µ\n",
    "        for page_num in range(0, total_pages):\n",
    "        # for page_num in range(0, 10):\n",
    "            page = pdf.pages[page_num]\n",
    "            print(f\"\\ræ­£åœ¨è§£æç¬¬ {page_num + 1} é¡µ...\", end='', flush=True)\n",
    "            \n",
    "            # æå–å½“å‰é¡µæ‰€æœ‰è¡¨æ ¼\n",
    "            table = page.extract_table(\n",
    "                # å‚è€ƒï¼š\n",
    "                # https://github.com/jsvine/pdfplumber?tab=readme-ov-file#table-extraction-settings\n",
    "                table_settings={\n",
    "                    \"vertical_strategy\": \"lines\",  # æŒ‰ç«–çº¿è¯†åˆ«åˆ—è¾¹ç•Œ\n",
    "                    \"horizontal_strategy\": \"lines\",  # æŒ‰æ¨ªçº¿è¯†åˆ«è¡Œè¾¹ç•Œ\n",
    "                    \"text_y_tolerance\": 10,  # æ–‡æœ¬å‚ç›´æ–¹å‘å®¹é”™\n",
    "                    \"text_x_tolerance\": 5,   # æ–‡æœ¬æ°´å¹³æ–¹å‘å®¹é”™\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # æå–é¡µé¢æ ‡é¢˜ï¼Œè§£æ(é¡¹ç›®ç±»å‹)\n",
    "            title_text = page.crop(bbox=[0, 0, 584, 130]).extract_text() or \"\"\n",
    "\n",
    "            construction_nature = \"\"\n",
    "\n",
    "            if title_text.find(\"æ–°å»º\") != -1 or title_text.find(\"æ–°å¼€å·¥\") != -1 :\n",
    "                construction_nature = \"æ–°å»º\"\n",
    "\n",
    "            if title_text.find(\"ç»­å»º\") != -1:\n",
    "                construction_nature = \"ç»­å»º\"\n",
    "            \n",
    "            # ä½¿ç”¨æ–°å‡½æ•°å¤„ç†è¡¨æ ¼æ•°æ®\n",
    "            table_data = process_table_rows(table, construction_nature)\n",
    "\n",
    "            if False:\n",
    "                print(f\"ğŸŒŸç¬¬ {page_num + 1} é¡µå¤„ç†åçš„æ•°æ®ï¼š\")\n",
    "                for row in table_data:\n",
    "                    print(row)\n",
    "\n",
    "            # å°†å¤„ç†åçš„æ•°æ®æ·»åŠ åˆ°æ€»æ•°æ®åˆ—è¡¨ä¸­\n",
    "            result_key_project_list.extend(table_data)\n",
    "\n",
    "        print(f\"\\rè§£æå®Œæˆï¼æ€»å…± {total_pages} é¡µã€‚\")\n",
    "    \n",
    "    return result_key_project_list\n",
    "\n",
    "def process_table_rows(table, construction_nature):\n",
    "    # å­˜å‚¨å½“å‰è¡¨æ ¼å¤„ç†åçš„æ•°æ®\n",
    "    # example:\n",
    "    # [\n",
    "    #     [\"é¡¹ç›®åç§°\", \"å»ºè®¾åœ°å€\", \"ä¸€çº§é¡¹ç›®é¢†åŸŸ\", \"äºŒçº§é¡¹ç›®é¢†åŸŸ\", \"å»ºè®¾æ€§è´¨(æ–°å»º/ç»­å»º)\"]\n",
    "    #     [â€¦â€¦], \n",
    "    # ]\n",
    "    result_list = []  \n",
    "\n",
    "    for index, row in enumerate(table):\n",
    "        # è·³è¿‡è¡¨å¤´è¡Œ\n",
    "        if index < 2:\n",
    "            continue  \n",
    "\n",
    "        # è§£æ„ä¸ºå•å…ƒæ ¼ï¼Œæ€»åºå·ã€åˆ†åºå·ã€é¡¹ç›®åç§°ã€å»ºè®¾åœ°å€\n",
    "        # ç§»é™¤ä¸¤ä¾§æ½œåœ¨çš„ç©ºæ ¼\n",
    "        total_seq_cell, sub_seq_cell, project_name_cell, construction_address_cell = [cell.strip() if cell else \"\" for cell in row]\n",
    "\n",
    "        if False:\n",
    "            print(f\"ğŸª¨åŸå§‹ {index + 1} è¡Œï¼š{row}\")\n",
    "\n",
    "        # æ¸…ç†é¡¹ç›®åç§°å•å…ƒæ ¼ï¼Œå»é™¤æ¢è¡Œç¬¦å’Œæ‹¬å·åŠå…¶åå†…å®¹\n",
    "        # \"æ•™è‚²ã€æ–‡åŒ–ã€ä½“è‚²åŠç¤¾ä¼šæœåŠ¡ï¼ˆ16é¡¹ï¼‰\" -> \"æ•™è‚²ã€æ–‡åŒ–ã€ä½“è‚²åŠç¤¾ä¼šæœåŠ¡\"\n",
    "        if not construction_address_cell or construction_address_cell == '':\n",
    "            project_name_cell = remove_after_first_paren(project_name_cell.replace(\"\\n\", \"\"))\n",
    "\n",
    "        global Level_1_Project_Domain \n",
    "        global Level_2_Project_Domain \n",
    "        global Level_3_Project_Domain \n",
    "\n",
    "        # total_seq_cell ä¸º 'ä¸€äºŒä¸‰å››äº”' å…¶ä¸­ä¸€ä¸ªæ±‰å­—ï¼Œåˆ™ä½¿ç”¨ project_name_cell ä½œä¸º ä¸€çº§é¡¹ç›®é¢†åŸŸ\n",
    "        if re.match(r'^[ä¸€äºŒä¸‰å››äº”]$', total_seq_cell):\n",
    "            Level_1_Project_Domain = project_name_cell\n",
    "            Level_2_Project_Domain = \"\"\n",
    "            Level_3_Project_Domain = \"\"\n",
    "            continue\n",
    "\n",
    "        if re.match(r'^ï¼ˆ[ä¸€äºŒä¸‰å››äº”]ï¼‰$', total_seq_cell):\n",
    "            Level_2_Project_Domain = project_name_cell\n",
    "            Level_3_Project_Domain = \"\"\n",
    "            continue\n",
    "\n",
    "        if total_seq_cell in ['I', 'â… ', 'â…¡', 'â…¢', 'â…£', 'II', 'III', 'IV', 'V', 'â…¤', 'VI']:\n",
    "            Level_3_Project_Domain = project_name_cell\n",
    "            continue\n",
    "\n",
    "        # è·³è¿‡å»ºè®¾åœ°å€ä¸ºç©ºçš„è¡Œ\n",
    "        if not construction_address_cell or construction_address_cell == '':\n",
    "            continue\n",
    "\n",
    "        # å»ºè®¾åœ°å€çš„æ¢è¡Œç¬¦å¤„ç†ä¸ºç©ºæ ¼\n",
    "        address_city = construction_address_cell.replace(\"\\n\", \" \")\n",
    "\n",
    "        refined_data = [\n",
    "            project_name_cell, \n",
    "            address_city, \n",
    "            Level_1_Project_Domain, \n",
    "            Level_2_Project_Domain,\n",
    "            Level_3_Project_Domain,\n",
    "            construction_nature\n",
    "        ]\n",
    "\n",
    "        if False:\n",
    "            print(f\"ğŸŒˆå·²ç»å¤„ç†ç¬¬ {index + 1} è¡Œï¼š{refined_data}\")\n",
    "\n",
    "        result_list.append(refined_data)\n",
    "\n",
    "    return result_list\n",
    "\n",
    "def remove_after_first_paren(text):\n",
    "    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç¬¬ä¸€ä¸ªå·¦æ‹¬å·åŠå…¶åé¢çš„æ‰€æœ‰å†…å®¹å¹¶æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²\n",
    "    return re.sub(r'ï¼ˆ.*', '', text)\n",
    "    \n",
    "if False:\n",
    "    result_key_project_list = extract_table_from_pdf(CONST_PDF_PATH) \n",
    "\n",
    "    print(f\"ğŸŒŸæ‰€æœ‰è¡¨æ ¼å¤„ç†åçš„æ•°æ®ï¼š\")\n",
    "    for row in result_key_project_list:\n",
    "        print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7681e0",
   "metadata": {},
   "source": [
    "### 1.3 ä½¿ç”¨ pandas æ•°æ®æ¸…æ´—\n",
    "\n",
    "è½¬æ¢ä¸º DataFrame å¹¶æ¸…æ´—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "edf8b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_dataframe(data, columns):\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    if False:\n",
    "        print(df.shape)       # è¾“å‡º (2, 2) â†’ è¡¨ç¤º 2 è¡Œ 2 åˆ—\n",
    "        print(df.columns)     # è¾“å‡º Index(['å§“å', 'å¹´é¾„'], dtype='object') â†’ åˆ—å\n",
    "        print(df.index)       # è¾“å‡º RangeIndex(start=0, stop=2, step=1) â†’ è¡Œç´¢å¼•\n",
    "        print(df.dtypes)      # è¾“å‡ºå„åˆ—æ•°æ®ç±»å‹ï¼ˆå¦‚ å§“å: objectï¼Œå¹´é¾„: int64ï¼‰\n",
    "        print(df.values)      # è¾“å‡º numpy æ•°ç»„å½¢å¼çš„åŸå§‹æ•°æ® â†’ [['å¼ ä¸‰' 20] ['æå››' 22]]\n",
    "    return df\n",
    "\n",
    "if False:\n",
    "    result = extract_table_from_pdf(CONST_PDF_PATH) \n",
    "    df = convert_to_dataframe(result, CONST_TARGET_HEADERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8632f",
   "metadata": {},
   "source": [
    "### 1.4 ä¿å­˜ç»“æœï¼ˆCSVï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5b5a99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_results(df, pdf_path, output_dir):\n",
    "\n",
    "    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„\n",
    "    output_csv = get_output_csv_path(pdf_path, output_dir)\n",
    "\n",
    "    # ä¿å­˜ä¸º CSVï¼ˆå…¼å®¹æ›´å¤šå·¥å…·ï¼Œå¦‚ Excelã€Pythonè¯»å–ï¼‰\n",
    "    # utf-8-sig è§£å†³ä¸­æ–‡ä¹±ç \n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\") \n",
    "    return output_csv\n",
    "\n",
    "def get_output_csv_path(pdf_path, output_dir):\n",
    "    \"\"\"\n",
    "    æ ¹æ®PDFæ–‡ä»¶åç”Ÿæˆè¾“å‡ºCSVæ–‡ä»¶è·¯å¾„\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: PDFæ–‡ä»¶è·¯å¾„\n",
    "        output_dir: è¾“å‡ºç›®å½•\n",
    "    \n",
    "    Returns:\n",
    "        ç”Ÿæˆçš„CSVæ–‡ä»¶å®Œæ•´è·¯å¾„\n",
    "    \"\"\"\n",
    "\n",
    "    # è·å–PDFæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰\n",
    "    pdf_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    # æ„é€ è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„\n",
    "    output_csv = os.path.join(output_dir, f\"{pdf_filename}_è§£æç»“æœ.csv\")\n",
    "    return output_csv\n",
    "\n",
    "if False:\n",
    "    result = extract_table_from_pdf(CONST_PDF_PATH) \n",
    "    df = convert_to_dataframe(result, CONST_TARGET_HEADERS)\n",
    "    save_results(df, CONST_PDF_PATH, CONST_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d41c8",
   "metadata": {},
   "source": [
    "\n",
    "### 1.5 æ•°æ®å¤„ç†ä¸»å‡½æ•°è¿è¡Œ (main)\n",
    "> ç»„ç»‡å„ä¸ªæ­¥éª¤å‡½æ•°è¿è¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e2829e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è§£æå®Œæˆï¼æ€»å…± 76 é¡µã€‚\n",
      "è§£æå®Œæˆ(2025-11-06 01:24:38)ï¼å…±æå–727æ¡é¡¹ç›®æ•°æ®ï¼Œå·²ä¿å­˜è‡³ï¼š\n",
      "- CSV: ./outputs/2024å¹´å››å·çœé‡ç‚¹é¡¹ç›®åå•_è§£æç»“æœ.csv\n",
      "\n",
      "è§£æç»“æœé¢„è§ˆï¼ˆå‰5æ¡ï¼‰ï¼š\n",
      "                 é¡¹ç›®åç§°     å»ºè®¾åœ°å€  ä¸€çº§é¡¹ç›®é¢†åŸŸ  äºŒçº§é¡¹ç›®é¢†åŸŸ ä¸‰çº§é¡¹ç›®é¢†åŸŸ å»ºè®¾æ€§è´¨\n",
      "0               å›½å®¶å®éªŒå®¤  å››å· å¤©åºœæ–°åŒº  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n",
      "1  ææ·±åœ°ä¸‹æä½è¾å°„æœ¬åº•å‰æ²¿ç‰©ç†å®éªŒè®¾æ–½  å‡‰å±±å· å†•å®å¿  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n",
      "2       å…‰åœºè°ƒæ§è£…ç½®åŠåœ°æ–¹é…å¥—é¡¹ç›®  å››å· å¤©åºœæ–°åŒº  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n",
      "3      å¤šæ€è€¦åˆè½¨é“äº¤é€šåŠ¨æ¨¡è¯•éªŒå¹³å°  å››å· å¤©åºœæ–°åŒº  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n",
      "4     ä¸­å›½åœ°éœ‡ç§‘å­¦å®éªŒåœºï¼ˆåœ¨å·éƒ¨åˆ†ï¼‰   æœ‰å…³å¸‚ï¼ˆå·ï¼‰  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n",
      "è§£æå®Œæˆï¼æ€»å…± 116 é¡µã€‚\n",
      "è§£æå®Œæˆ(2025-11-06 01:24:38)ï¼å…±æå–833æ¡é¡¹ç›®æ•°æ®ï¼Œå·²ä¿å­˜è‡³ï¼š\n",
      "- CSV: ./outputs/2025å¹´å››å·çœé‡ç‚¹é¡¹ç›®åå•_è§£æç»“æœ.csv\n",
      "\n",
      "è§£æç»“æœé¢„è§ˆï¼ˆå‰5æ¡ï¼‰ï¼š\n",
      "                    é¡¹ç›®åç§°     å»ºè®¾åœ°å€  ä¸€çº§é¡¹ç›®é¢†åŸŸ  äºŒçº§é¡¹ç›®é¢†åŸŸ ä¸‰çº§é¡¹ç›®é¢†åŸŸ å»ºè®¾æ€§è´¨\n",
      "0          å…‰åœºè°ƒæ§è£…ç½®åŠåœ°æ–¹é…å¥—é¡¹ç›®  å››å· å¤©åºœæ–°åŒº  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n",
      "1                 ç£æµ®é£è¡Œé£æ´  å››å· å¤©åºœæ–°åŒº  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n",
      "2                å‡†ç¯å¯¹ç§°ä»¿æ˜Ÿå™¨  å››å· å¤©åºœæ–°åŒº  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n",
      "3          çº¢å¤–å¤ªèµ«å…¹è‡ªç”±ç”µå­æ¿€å…‰è£…ç½®  æˆéƒ½å¸‚ åŒæµåŒº  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n",
      "4  ä¸­å›½åœ°éœ‡ç§‘å­¦å®éªŒåœºå»ºè®¾å·¥ç¨‹é¡¹ç›®ï¼ˆå››å·éƒ¨åˆ†ï¼‰   æœ‰å…³å¸‚ï¼ˆå·ï¼‰  åŸºç¡€è®¾æ–½é¡¹ç›®  æ–°å‹åŸºç¡€è®¾æ–½          ç»­å»º\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def mainDataPreprocess(pdf_path, out_dir, target_columns):\n",
    "    # æå–è¡¨æ ¼æ•°æ®\n",
    "    raw_data = extract_table_from_pdf(pdf_path)\n",
    "    \n",
    "    # è½¬æ¢ä¸ºDataFrame\n",
    "    df = convert_to_dataframe(raw_data, columns=target_columns)\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    saved_path = save_results(df, pdf_path, out_dir)\n",
    "\n",
    "    # è·å–å½“å‰æ—¶é—´\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # è¾“å‡ºç»“æœä¿¡æ¯\n",
    "    print(f\"è§£æå®Œæˆ({current_time})ï¼å…±æå–{len(df)}æ¡é¡¹ç›®æ•°æ®ï¼Œå·²ä¿å­˜è‡³ï¼š\")\n",
    "    print(f\"- CSV: {saved_path}\")\n",
    "    \n",
    "    # æ‰“å°å‰5æ¡æ•°æ®éªŒè¯ç»“æœ\n",
    "    print(\"\\nè§£æç»“æœé¢„è§ˆï¼ˆå‰5æ¡ï¼‰ï¼š\")\n",
    "    print(df.head())\n",
    "\n",
    "# è¿è¡Œä¸»ç¨‹åº\n",
    "if __name__ == \"__main__\":\n",
    "    mainDataPreprocess(\n",
    "        pdf_path=\"./assets/2024å¹´å››å·çœé‡ç‚¹é¡¹ç›®åå•.pdf\", \n",
    "        out_dir=CONST_OUTPUT_DIR,\n",
    "        target_columns=CONST_TARGET_HEADERS\n",
    "    )\n",
    "\n",
    "    mainDataPreprocess(\n",
    "        pdf_path=\"./assets/2025å¹´å››å·çœé‡ç‚¹é¡¹ç›®åå•.pdf\", \n",
    "        out_dir=CONST_OUTPUT_DIR,\n",
    "        target_columns=CONST_TARGET_HEADERS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7a24e",
   "metadata": {},
   "source": [
    "## 2. å…³é”®è¯æå–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8985c54",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"stopwords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stopwords = [line.strip() for line in f.readlines()]\n",
    "\n",
    "def extract_keywords(text):\n",
    "    words = jieba.lcut(text)  # ä¸­æ–‡åˆ†è¯\n",
    "    return [word for word in words if word not in stopwords and len(word) > 1]\n",
    "\n",
    "if not False:\n",
    "\n",
    "  # åŠ è½½æ•°æ®\n",
    "  df_2024 = pd.read_csv(\"./outputs/2024å¹´å››å·çœé‡ç‚¹é¡¹ç›®åå•_è§£æç»“æœ.csv\")\n",
    "  df_2025 = pd.read_csv(\"./outputs/2025å¹´å››å·çœé‡ç‚¹é¡¹ç›®åå•_è§£æç»“æœ.csv\")\n",
    "\n",
    "  # æå–2024å’Œ2025å¹´å…³é”®è¯\n",
    "  keywords_2024 = []\n",
    "  keywords_2025 = []\n",
    "\n",
    "  for name in df_2024[\"é¡¹ç›®åç§°\"]:\n",
    "      keywords_2024.extend(extract_keywords(str(name)))\n",
    "  for name in df_2025[\"é¡¹ç›®åç§°\"]:\n",
    "      keywords_2025.extend(extract_keywords(str(name)))\n",
    "\n",
    "  print(\"ğŸ³2024å¹´å…³é”®è¯ï¼š\\n\", pd.Series(keywords_2024).value_counts().head(60))\n",
    "  # print(\"ğŸ³2025å¹´å…³é”®è¯ï¼š\\n\", pd.Series(keywords_2025).value_counts().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9608b",
   "metadata": {},
   "source": [
    "## 2.1 äº§ä¸šå…³é”®è¯ä½“ç³»æ„å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_keywords = {\n",
    "    \"äº¤é€šç‰©æµ\": [\"é“è·¯\", \"é«˜é€Ÿ\", \"æœºåœº\", \"æ¸¯å£\", \"ç‰©æµ\", \"è½¨é“\", \"å…¬è·¯\"],\n",
    "    \"æ–°èƒ½æº\": [\"å…‰ä¼\", \"é£ç”µ\", \"æ°¢èƒ½\", \"é”‚ç”µæ± \", \"æ–°èƒ½æºæ±½è½¦\", \"å‚¨èƒ½\"],\n",
    "    \"æ•°å­—ç»æµ\": [\"5G\", \"å¤§æ•°æ®\", \"äººå·¥æ™ºèƒ½\", \"ç®—åŠ›\", \"äº‘è®¡ç®—\", \"æ•°æ®ä¸­å¿ƒ\"],\n",
    "    \"å…ˆè¿›åˆ¶é€ \": [\"èŠ¯ç‰‡\", \"èˆªç©º\", \"è£…å¤‡\", \"æ™ºèƒ½\", \"æœºå™¨äºº\", \"åŠå¯¼ä½“\"],\n",
    "    \"ç»¿è‰²ä½ç¢³\": [\"ç¯ä¿\", \"ç¢³æ•é›†\", \"æ±¡æ°´\", \"ç”Ÿæ€\", \"èŠ‚èƒ½\", \"å¾ªç¯ç»æµ\"],\n",
    "    \"æ°‘ç”ŸåŸºå»º\": [\"å­¦æ ¡\", \"åŒ»é™¢\", \"ä¿éšœæˆ¿\", \"æ°´åˆ©\", \"ä¾›æ°´\", \"å…»è€\"]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem-course-works",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
